# -*- coding: utf-8 -*-
import sys
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

import requests
from bs4 import BeautifulSoup
import json
import time
import re
import sqlite3
from typing import Dict, Optional

class NaverPlaceCrawler:
    """ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ì—ì„œ ìˆ˜ì˜ì¥ ì •ë³´ í¬ë¡¤ë§"""

    def __init__(self):
        self.naver_client_id = "VDnVKXoA66gaC4cz3vzc"
        self.naver_client_secret = "XuMSFxDf35"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })

    def search_naver_place(self, pool_name: str, address: str) -> Optional[Dict]:
        """ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ìœ¼ë¡œ í”Œë ˆì´ìŠ¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            # ì£¼ì†Œì—ì„œ êµ¬ ì •ë³´ ì¶”ì¶œ
            district = ""
            if "êµ¬" in address:
                parts = address.split()
                for part in parts:
                    if "êµ¬" in part:
                        district = part
                        break

            search_query = f"{pool_name} {district}"

            response = requests.get(
                "https://openapi.naver.com/v1/search/local.json",
                headers={
                    "X-Naver-Client-Id": self.naver_client_id,
                    "X-Naver-Client-Secret": self.naver_client_secret
                },
                params={
                    "query": search_query,
                    "display": 5
                }
            )

            if response.status_code == 200:
                items = response.json().get("items", [])

                for item in items:
                    title = item.get("title", "").replace("<b>", "").replace("</b>", "")
                    item_address = item.get("address", "")

                    # ì´ë¦„ì´ ìœ ì‚¬í•œì§€ í™•ì¸
                    if pool_name[:4] in title or title[:4] in pool_name:
                        return {
                            "title": title,
                            "category": item.get("category", ""),
                            "telephone": item.get("telephone", ""),
                            "address": item_address,
                            "roadAddress": item.get("roadAddress", ""),
                            "link": item.get("link", "")
                        }

            time.sleep(0.1)
            return None

        except Exception as e:
            print(f"  âœ— ë„¤ì´ë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)[:50]}")
            return None

    def extract_price_from_description(self, description: str) -> Optional[int]:
        """ì„¤ëª…ì—ì„œ ê°€ê²© ì¶”ì¶œ"""
        if not description:
            return None

        patterns = [
            r'(\d{1,2}),(\d{3})\s*ì›',  # 3,500ì›
            r'(\d{4,5})\s*ì›',           # 3500ì›
            r'(\d{1,2})\s*ë§Œ\s*(\d{0,4})\s*ì›',  # 1ë§Œ 5000ì›
        ]

        for pattern in patterns:
            match = re.search(pattern, description)
            if match:
                if 'ë§Œ' in description[max(0, match.start()-2):match.end()+2]:
                    man = int(match.group(1))
                    cheon = int(match.group(2)) if len(match.groups()) > 1 and match.group(2) else 0
                    return man * 10000 + cheon
                elif len(match.groups()) > 1:
                    return int(match.group(1) + match.group(2))
                else:
                    price = int(match.group(1))
                    if price >= 1000:
                        return price

        return None

    def get_public_pool_prices(self) -> Dict[str, int]:
        """êµ¬ë¯¼ì²´ìœ¡ì„¼í„° ë“± ê³µê³µ ìˆ˜ì˜ì¥ í‘œì¤€ ê°€ê²©"""
        return {
            "êµ¬ë¯¼ì²´ìœ¡ì„¼í„°": 3500,
            "êµ¬ë¯¼íšŒê´€": 3500,
            "ê³µê³µìˆ˜ì˜ì¥": 3000,
            "êµ¬ë¦½ìˆ˜ì˜ì¥": 3500,
            "ì²´ìœ¡ê´€": 3500,
            "ë³µì§€ê´€": 3000,
            "ì²­ì†Œë…„": 2500,
            "ì–´ë¦°ì´": 2000,
        }

    def crawl_pool_info(self, pool_name: str, address: str) -> Dict:
        """ìˆ˜ì˜ì¥ ì •ë³´ í¬ë¡¤ë§"""
        result = {
            "name": pool_name,
            "address": address,
            "daily_price": None,
            "free_swim_price": None,
            "phone": None,
            "category": None
        }

        print(f"  â†’ ë„¤ì´ë²„ ê²€ìƒ‰ ì¤‘...")

        # 1. ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ê²€ìƒ‰
        place_info = self.search_naver_place(pool_name, address)

        if not place_info:
            print(f"  âœ— ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ì—†ìŒ")
            return result

        # 2. ì „í™”ë²ˆí˜¸, ì¹´í…Œê³ ë¦¬ ì €ì¥
        result["phone"] = place_info.get("telephone", "")
        result["category"] = place_info.get("category", "")

        print(f"  âœ“ í”Œë ˆì´ìŠ¤ ë°œê²¬: {place_info['title']}")
        print(f"    ì¹´í…Œê³ ë¦¬: {result['category']}")

        # ë„¤ì´ë²„ ì§€ì—­ ê²€ìƒ‰ APIëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ê°€ê²© ì •ë³´ë¥¼ ì œê³µí•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
        # ì—¬ê¸°ì„œëŠ” ê¸°ë³¸ ì •ë³´ë¥¼ ì±„ìš°ëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš©í•˜ê³ , 
        # ì‹¤ì œ ê°€ê²©ì€ ë³„ë„ì˜ ì›¹ í¬ë¡¤ëŸ¬(price_crawler.py)ì—ì„œ ê°€ì ¸ì˜¤ë„ë¡ ìœ ë„í•©ë‹ˆë‹¤.
        
        return result

    def update_database(self):
        """DBì˜ ëª¨ë“  ìˆ˜ì˜ì¥ ì •ë³´ ì—…ë°ì´íŠ¸"""
        conn = sqlite3.connect('swimming_pools.db')
        cursor = conn.cursor()

        # ê°€ê²©ì´ ì—†ê±°ë‚˜ ê¸°ë³¸ê°’ì¸ ìˆ˜ì˜ì¥ë§Œ ì—…ë°ì´íŠ¸
        cursor.execute('''
            SELECT id, name, address
            FROM swimming_pools
            WHERE daily_price IS NULL
               OR daily_price IN (5000, 10000)
               OR free_swim_price IS NULL
               OR free_swim_price IN (4000, 8000)
            ORDER BY id
        ''')

        pools = cursor.fetchall()
        total = len(pools)

        print(f"\n{'='*80}")
        print(f"ğŸŠ {total}ê°œ ìˆ˜ì˜ì¥ ì •ë³´ ì—…ë°ì´íŠ¸ ì‹œì‘")
        print(f"{'='*80}\n")

        updated_count = 0

        for i, (pool_id, name, address) in enumerate(pools):
            print(f"[{i+1}/{total}] {name}")

            # ì •ë³´ í¬ë¡¤ë§
            info = self.crawl_pool_info(name, address)

            # DB ì—…ë°ì´íŠ¸
            updates = []
            params = []

            if info["daily_price"]:
                updates.append("daily_price = ?")
                params.append(info["daily_price"])

            if info["free_swim_price"]:
                updates.append("free_swim_price = ?")
                params.append(info["free_swim_price"])

            if info["phone"] and info["phone"] != "":
                updates.append("phone = ?")
                params.append(info["phone"])

            if updates:
                params.append(pool_id)
                query = f"UPDATE swimming_pools SET {', '.join(updates)} WHERE id = ?"
                cursor.execute(query, params)
                updated_count += 1

            conn.commit()
            time.sleep(0.3)  # ì„œë²„ ë¶€í•˜ ë°©ì§€
            print()

        conn.close()

        print(f"\n{'='*80}")
        print(f"âœ… ì—…ë°ì´íŠ¸ ì™„ë£Œ: {updated_count}ê°œ ìˆ˜ì˜ì¥")
        print(f"{'='*80}")

if __name__ == "__main__":
    print("ğŸŠ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ê¸°ë°˜ ìˆ˜ì˜ì¥ ê°€ê²© í¬ë¡¤ëŸ¬\n")

    crawler = NaverPlaceCrawler()
    crawler.update_database()
